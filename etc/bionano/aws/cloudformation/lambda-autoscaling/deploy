#!/usr/bin/env bash
set -e

if [ $# -eq 0 ]; then
	echo ""
    echo "    Package and deploy the CCC autoscaling lambdas to AWS"
    echo ""
    echo "    -k/--key         AWS Access Key Id"
    echo "    -s/--secret      AWS Access Key Secret"
    echo "    -n/--subnets     AWS subnet ids (comma separated)"
    echo "    -g/--secgroup    AWS security group ids (comma separated)"
    echo "    -t/--tag         BNP env tag (dev|qa|prod). Defaults to dev. Determines deploy region"
    echo "    -d/--dryrun      Build but do not actually deploy"
    echo ""
    exit 0
fi

# Use -gt 1 to consume two arguments per pass in the loop (e.g. each
# argument has a corresponding value to go with it).
# Use -gt 0 to consume one or more arguments per pass in the loop (e.g.
# some arguments don't have a corresponding value to go with it such
# as in the --default example).
# note: if this is set to -gt 0 the /etc/hosts part is not recognized ( may be a bug )

BNR_ENVIRONMENT="dev"

while [[ $# -gt 1 ]]
do
key="$1"

case $key in
    -d|--dryrun)
    DRYRUN="true"
    ;;
    -k|--key)
    AWS_ACCESS_KEY_ID="$2"
    shift # past argument
    ;;
    -s|--secret)
    AWS_SECRET_ACCESS_KEY="$2"
    shift # past argument
    ;;
    -t|--tag)
    BNR_ENVIRONMENT="$2"
    shift # past argument
    ;;
    -n|--subnets)
    SUBNETS="$2"
    shift # past argument
    ;;
    -g|--secgroup)
    SEC_GROUPS="$2"
    shift # past argument
    ;;
    *)
            # unknown option
    ;;
esac
shift # past argument or value
done

if [ -n "$DRYRUN" ] && [ "$DRYRUN" == "true" ] ; then
    echo "DRYRUN: Not sending to AWS"
fi

REGION="us-west-2"

case "$BNR_ENVIRONMENT" in
        dev)
            REGION="us-west-2"
            ;;
        qa)
            REGION="us-east-1"
            ;;
        prod)
            REGION="us-east-1"
            ;;
        test)
            REGION="us-west-1"
            ;;
esac

DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
PROJECTROOT=$DIR/../../../../..

# echo "Validating CF template..."
# AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY aws cloudformation validate-template --template-body file://$DIR/cf-ccc-scaling.json

echo "Compiling haxe->javascript..."
pushd $PROJECTROOT
docker-compose -f docker-compose.compile.yml run compile-lambda
popd
#Compiled js goes here (also the package.json)
LAMBDA_SRC="$PROJECTROOT/build/lambda-autoscaling"

echo "Building lambda package..."
LAMBDA_ZIP_FOLDER="$PROJECTROOT/build/lambda-autoscaling-zip"
rm -rf $LAMBDA_ZIP_FOLDER
mkdir -p $LAMBDA_ZIP_FOLDER
docker run --rm -ti -v $LAMBDA_SRC:/src -v $LAMBDA_ZIP_FOLDER:/destination dionjwa/aws-lambda-builder -s /src -d /destination

NAME=`cat $DIR/src/package.json | jq -r ".name"`
VERSION=`cat $DIR/src/package.json | jq -r ".version"`
ZIP_NAME="lambda-${NAME}-${VERSION}.zip"
ZIP_FILE="$LAMBDA_ZIP_FOLDER/$ZIP_NAME"
S3BUCKET="bionano-devops-build-artifacts-$REGION"
S3KEY="lambdas/ccc/$ZIP_NAME"
S3PATH="s3://${S3BUCKET}/${S3KEY}"
STACKNAME="${BNR_ENVIRONMENT}-CCC-Lambda-Scaling"

echo "Uploading lambda package to S3..."
#Now copy to S3 and get the package name
docker run --rm -it -e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID -e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY -v $ZIP_FILE:/tmp/$ZIP_NAME docker.io/garland/aws-cli-docker aws s3 cp /tmp/$ZIP_NAME $S3PATH

#Check if the stack already exists
set +e
eval AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY aws --region $REGION cloudformation describe-stacks --stack-name "$STACKNAME" > /dev/null 2>&1
ISSTACK=$?
set -e

PARAMETERSTRING='[{"ParameterKey":"S3Bucket","ParameterValue":"S3BUCKET"},{"ParameterKey":"S3Key","ParameterValue":"S3KEY"},{"ParameterKey":"BionanoEnvironment","ParameterValue":"BNR_ENVIRONMENT"},{"ParameterKey":"SubNetIds","ParameterValue":"SUBNETS"},{"ParameterKey":"SecGroupIds","ParameterValue":"SEC_GROUPS"}]'
PARAMETERSTRING=${PARAMETERSTRING/S3BUCKET/$S3BUCKET}
PARAMETERSTRING=${PARAMETERSTRING/S3KEY/$S3KEY}
PARAMETERSTRING=${PARAMETERSTRING/BNR_ENVIRONMENT/$BNR_ENVIRONMENT}
PARAMETERSTRING=${PARAMETERSTRING/SUBNETS/$SUBNETS}
PARAMETERSTRING=${PARAMETERSTRING/SEC_GROUPS/$SEC_GROUPS}
echo $PARAMETERSTRING > parameters.json

if [ $ISSTACK == "0" ] ; then
	echo "Stack exists, updating..."
    if [ -z ${DRYRUN+x} ] ; then
        AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY \
        aws --region $REGION cloudformation update-stack \
            --stack-name $STACKNAME \
            --parameters file://$DIR/parameters.json \
            --capabilities CAPABILITY_IAM \
            --template-body file://$DIR/cf-ccc-scaling.json
    fi
else
	echo "Stack does not exist, creating..."
    if [ -z ${DRYRUN+x} ] ; then
        AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY \
    	aws --region $REGION cloudformation create-stack \
    		--stack-name $STACKNAME \
            --parameters file://$DIR/parameters.json \
            --capabilities CAPABILITY_IAM \
            --template-body file://$DIR/cf-ccc-scaling.json
    fi
fi

